# Supabase (client-side)
EXPO_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
EXPO_PUBLIC_SUPABASE_ANON_KEY=your-anon-key

# Supabase Edge Functions (server-side, configuré dans Supabase Dashboard)
# LLM_API_URL=http://localhost:11434/v1        # Ollama (dev)
# LLM_API_URL=https://generativelanguage.googleapis.com/v1beta  # Gemini (prod)
# LLM_MODEL=llama3:8b                          # Ollama (dev)
# LLM_MODEL=gemini-2.5-flash                   # Gemini (prod)
# LLM_API_KEY=                                  # Vide pour Ollama, AIza... pour Gemini
# LLM_PROVIDER=                                 # (optionnel) Force le provider : openai | gemini
# LLM_CACHE_TTL=3600                            # (optionnel) TTL cache contexte Gemini en secondes (0 = désactivé)

# Prefetch (client-side)
# EXPO_PUBLIC_DISABLE_PREFETCH=true              # (optionnel) Désactive le prefetch A/B (réduit les tokens de moitié)
